### 2.1 Related Work
In recent years, significant progress has been made in the application of artificial intelligence in the field of mental health support. The dialogue system based on natural language processing, such as Xiaoyu AI and MindScan, has been widely explored and deployed as digital mental health assistants. Researches show that these chat bots can play a positive role in intervention for moderate anxiety and depression.

In terms of the interaction mode, more and more systems are introducing voice interface to improve the user experience. For example, Siri can identify 128 emotional states through voiceprint analysis. When it detects anxiety, it will automatically play customized white noise. When it recognizes joy, the conversation interface will bloom with a celebratory animation.

However, although recent technology can realize short-term conversation understanding and immediate response, most systems are still lack of continued tracking of users' long-term mental state and the ability of user modeling.



### 2.2 Key Challenges
Our project faces several key technical challenges in building the AI mental assistant, in which long-term memory mechanism and speech recognition system are two core difficulties.
#### 2.2.1 Long-term Memory
When patients communicate with AI mental assistants, traditional dialogue systems need to repeatedly explore the patient's living habits and personality during each consultation. This rise the problem of traditional dialogue systems which only maintain conversation-level context memory rather than persistently store and retrieve key information across sessions. This project tend to deal with the following challenges:
- How to automatically identify and reserve the users' personality and habits as well as meaningful mental events from the consultation. 
- At the same time, selectively expired information forgetting to avoid information redundancy and contradictions is also a difficult task.
- Different users have significant differences in their expression methods. A general architecture can not adapt to individual needs accurately. Therefore the assistant need to build user profiles.

#### 2.2.2 Speech Recognition
Mental consultation is often accompanied by a lot of scenes that require descriptive text, and users may not be willing to text when they are feeling down. So speech interaction is very necessary in the project, but it is facing the following difficulties:
- Mental consultation contains a lot of pauses, repeats, interjections and some incomplete sentences. This requires a high level of comprehension ability of the model.
- Delay in speech transcription will disrupt the flow of conversation.

 