#!/usr/bin/env python3
"""
æµ‹è¯•ç¦»çº¿æ¨¡å¼åŠ è½½æ¨¡å‹
"""

import os
import sys

def test_offline_model_loading():
    """æµ‹è¯•ç¦»çº¿æ¨¡å¼åŠ è½½æ¨¡å‹"""
    print("æµ‹è¯•ç¦»çº¿æ¨¡å¼åŠ è½½SentenceTransformeræ¨¡å‹...")
    
    # è®¾ç½®ç¦»çº¿æ¨¡å¼
    os.environ['HF_HUB_OFFLINE'] = '1'
    print("âœ“ å·²è®¾ç½®ç¦»çº¿æ¨¡å¼")
    
    try:
        # å¯¼å…¥å¿…è¦çš„åº“
        from sentence_transformers import SentenceTransformer
        print("âœ“ æˆåŠŸå¯¼å…¥SentenceTransformer")
        
        # å°è¯•åŠ è½½æ¨¡å‹
        print("æ­£åœ¨åŠ è½½æ¨¡å‹ 'all-MiniLM-L6-v2'...")
        model = SentenceTransformer('all-MiniLM-L6-v2')
        print("âœ“ æ¨¡å‹åŠ è½½æˆåŠŸ!")
        
        # æµ‹è¯•æ¨¡å‹åŠŸèƒ½
        print("æµ‹è¯•æ¨¡å‹ç¼–ç åŠŸèƒ½...")
        sentences = ["è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•å¥å­", "è¿™æ˜¯å¦ä¸€ä¸ªæµ‹è¯•å¥å­"]
        embeddings = model.encode(sentences)
        print(f"âœ“ ç¼–ç æˆåŠŸï¼Œç”Ÿæˆäº† {len(embeddings)} ä¸ªå‘é‡ï¼Œæ¯ä¸ªå‘é‡ç»´åº¦: {len(embeddings[0])}")
        
        return True
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        print("\nå¯èƒ½çš„è§£å†³æ–¹æ¡ˆ:")
        print("1. ç¡®ä¿æ¨¡å‹å·²ä¸‹è½½å¹¶ç¼“å­˜")
        print("2. æ£€æŸ¥ç¼“å­˜ç›®å½•æƒé™")
        print("3. å°è¯•é‡æ–°ä¸‹è½½æ¨¡å‹:")
        print("   - è®¾ç½®ç¯å¢ƒå˜é‡: set HF_ENDPOINT=https://hf-mirror.com")
        print("   - ç„¶åé‡æ–°è¿è¡Œæ­¤è„šæœ¬")
        return False

def check_cache_status():
    """æ£€æŸ¥ç¼“å­˜çŠ¶æ€"""
    print("æ£€æŸ¥æ¨¡å‹ç¼“å­˜çŠ¶æ€...")
    
    # æ£€æŸ¥ç¼“å­˜ç›®å½•
    cache_dirs = [
        os.path.expanduser("~/AppData/Local/huggingface/"),
        os.path.expanduser("~/.cache/huggingface/"),
    ]
    
    model_name = "sentence-transformers/all-MiniLM-L6-v2"
    
    found = False
    for cache_dir in cache_dirs:
        if os.path.exists(cache_dir):
            # æ£€æŸ¥hubç›®å½•
            hub_dir = os.path.join(cache_dir, "hub")
            if os.path.exists(hub_dir):
                # æŸ¥æ‰¾æ¨¡å‹ç›®å½•
                for item in os.listdir(hub_dir):
                    if "all-MiniLM-L6-v2" in item:
                        model_path = os.path.join(hub_dir, item)
                        if os.path.exists(model_path):
                            print(f"âœ“ åœ¨ {model_path} æ‰¾åˆ°æ¨¡å‹ç¼“å­˜")
                            found = True
                            # æ˜¾ç¤ºç¼“å­˜å¤§å°
                            total_size = 0
                            for dirpath, dirnames, filenames in os.walk(model_path):
                                for f in filenames:
                                    fp = os.path.join(dirpath, f)
                                    if os.path.exists(fp):
                                        total_size += os.path.getsize(fp)
                            print(f"  ç¼“å­˜å¤§å°: {total_size / (1024*1024):.1f} MB")
    
    if not found:
        print("âš ï¸  æœªæ‰¾åˆ°æ¨¡å‹ç¼“å­˜")
    
    return found

if __name__ == "__main__":
    print("AIå¿ƒç†å­¦å®¶ç¦»çº¿æ¨¡å‹æµ‹è¯•å·¥å…·")
    print("=" * 30)
    
    # æ£€æŸ¥ç¼“å­˜
    has_cache = check_cache_status()
    
    if has_cache:
        # æµ‹è¯•ç¦»çº¿åŠ è½½
        success = test_offline_model_loading()
        if success:
            print("\nğŸ‰ ç¦»çº¿æ¨¡å¼æµ‹è¯•æˆåŠŸï¼")
            print("æ‚¨çš„æ¨¡å‹å¯ä»¥åœ¨æ²¡æœ‰ç½‘ç»œè¿æ¥çš„æƒ…å†µä¸‹æ­£å¸¸å·¥ä½œã€‚")
        else:
            print("\nâŒ ç¦»çº¿æ¨¡å¼æµ‹è¯•å¤±è´¥ã€‚")
            print("è¯·æ£€æŸ¥ä¸Šè¿°é”™è¯¯ä¿¡æ¯å¹¶å°è¯•è§£å†³æ–¹æ¡ˆã€‚")
    else:
        print("\nâš ï¸  æœªæ‰¾åˆ°æ¨¡å‹ç¼“å­˜ï¼Œè¯·å…ˆä¸‹è½½æ¨¡å‹:")
        print("1. è®¾ç½®ç¯å¢ƒå˜é‡: set HF_ENDPOINT=https://hf-mirror.com")
        print("2. è¿è¡Œåº”ç”¨è®©æ¨¡å‹è‡ªåŠ¨ä¸‹è½½")
        print("3. æˆ–æ‰‹åŠ¨ä¸‹è½½æ¨¡å‹æ–‡ä»¶")